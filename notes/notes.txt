type system supports both extensional and intensional definitions of a type.
they are treated as mutually dependent descriptors.
Thus an extensional type can be defined as the explicit list of all the other types which share its qualities and an intensional type can be defined as the explicit list of the qualities which other types must possess.
The distinction betwen the two approaches to definition is that extensional definitions of type can be reasoned about simply by referring to the list defined for that type whereas intensional types rely more on inference about whether the appropriate qualities are exhibited.

ASC compiles to an arch-independent assembly.
the assembly has an infinite number of general purpose registers.
it also has a set number of special registers.
	- Program Counter
	- Base Pointer
	- Zero
Data types correspond to the data types in ASC.
Operations are
	- Add
	- Subtract
	- Multiply
	- Quotient
	- Remainder

ASC syntax is created by patterns.
There are a few notations which are determined using characters rather than symbols.
This allows these notations to be represented with any format the programmer may chose.
These character notations are:
	-function declaration
	-function definition
	-sequence definition
	-sequence access
	-sequence introspection
	-type declaration
	-type assertion
	-type introspection
	-module definition
	-module access
	-conditional evaluation

The function declaration specifies the name of the function and the names of each parameter.
Function declarations may optionally specify a generic definition of the function.
A function definition specifies the types allowed for each parameter and a definition which is applied when parameters of those types are given to the function.

How do to sequence definition with just types and no names?

{1 2 3} `a sequence of constants`
{long long short} `a sequence with fields named "long", "long", "short"`
Sequence(long long short) `a sequence with fields typed long, long, and short`
Sequence(100) `a sequence with 100 fields`
Should a sequence be allowed with no default values? No.

Characters which are used directly in syntax.
().:;"'`[]{}&#^@

Default symbols...
( ) [ ] { } . .. : " ' ` & # ## @ ^ ? ??

Function declaration:
name (p1 p2 p...) = expr(p1 p2 p...)
name (p1 p2 p...) = expr(p1)
name (p1 p2 p...) = p3 {expr1(p1) expr2(p...) p3 = expr3(p2)}
name (p1 p2 p...) = p3 r... {p3 = p1 r... = p...}
name (p1 = x p2 = y p... = z) = p3 {p3 = expr()}
name (`...`) = p3 begin yeild name `returns in the immediate context`
name (`...`) = p3 begin end name `returns to call site`

Function call
name()

Pointer syntax just overloads the "@" character.
@ of any type except location generates a location.
@ of a location dereferences it.
actually makes things safer.
if you have nested structures then you don't need pointers to pointers because
you would use data type declarations to assert a specific memory layout.

Types are viewed as non-distinct geometric formations.
The size, shape, positioning, and dimensions of a form are not known.
Two things are considered: what (non-descript) features may be present on a form, and what features are shared between two forms.
Types can be defined as a unique form, a combination of multiple forms, a difference of forms, or a superposition of multiple forms.
A combination exhibits all the features of a collection of forms as a unique formation.
A difference exhibits all the features present in one form that are not shared with another.
A superposition is not a unique form, but instead may simultaneously exhibit any one form in a collection of existing forms.
A sequence is then an ordered collection of forms.
A function is a transformation from one collection of forms to another.
The types of functions and sequences are also represented as forms.

AND /\
OR \/
NOT ~

notation prefix is semicolon ;


Continuation design:
To implement full continuations, they must have 6 capabilities...
1.) Asymmetric; be able to move control back to the point where the continuation was called.
2.) Stackful; act like a regular function with its own context and stack.
3.) Delimited; have a finite definition that doesn't contain the entire program.
4.) Multi-prompt; ability to be nested and recursive.
5.) Reentrant; dynamically capture the program state at a given point as a callable continuation.
6.) Cloneable; ability to duplicate any continuation object.

Continuations as functions:
	- Dynamic extent enables 1, 2, 3, and 4
	- Function ends by returning to call site enables 1
	- Function ends by continuing to the next lexical control point enables 2
	- Declare a continuation as an immediate function enables 5
	- Treating continuations as first-class functions enables 6

Continuations only need dynamic extent and a delimited capture.
A delimited capture works like call/cc but only includes the lexical extent of its context.
The exclamation point (!) captures its context.
actually the exclamation point isn't necessary because you can do a lot more using simple closures.

So, now, full delimited continuations.
Asymmetric:

	cont () = {}
	f() = { ? abort Null }

a concern is that non-terminating control flow can cause memory leaking by dynamically generating contexts.

Functions in ASC can be defined using one single expression or two separate expressions.

A program is executed by evaluation.
Evaluation involves the process of applying functions and reducing them to their return parameters.
Through the process of evaluation, the program may change state and behavior.
Each time a program changes state, a mode is implicitly created.
A mode represents everything that is known about the program at the point where the mode is created.
Modes can be nested and have similar extent to scope, however modes are also affected by assignment and conditional evaluation as these both are ways where a program may change its own state.

How to do quoted macros and stuff like the backquote in common lisp?
A good example is forcing heap allocated variables to work like regular variables...
; . (x:Symbol) = ?? & (x) == Box Heap-Lookup(x) x

ASC doesn't really require an IR because it's already at C's level.
What it needs is a few operators for binary crap with registers.

Top-down semantic description sucks, but is helpful for describing the interaction of types with a dynamic program.

Evaluation schemes for Notation parameters.
Normal evaluation is implicit so captures expressions are evaluated before the notation is applied.
Deferred evaluation forces a captured expression to be preserved until after to notation is applied.
A parameter that has been deferred can be evaluated during the notation application by writing it by itself inside parentheses.

``Ex``

T = [value]
U = [value]
V = [value]

; . (x:T) = f(x) `normal`
; . (,x:U) = f(x) `deferred`
; . (,x:V) = f((x)) `deferred forced eval`

j:T = value
j `=> f(value), j is evaluated before f is called`

k:U = value n:U = value
(k + n):U `=> f(k + n), expression is evaluated after f is called`

h(x) = x:V
l:V = value
h(l) `=> f(value), l is forced to be evaluated before f is called`

if two types are alike? what does that represent?

Zero is a superposition of all zero values in the number tower.

0 = [0 +0 0.0]

Notation for conditionals:
Single conditional "if"... ? cond exp
conditional "if-else"... ?? cond exp exp
condition uses the following comparisions and boolean operators

Generic Comparison:
Equal		=

Numerical Comparisons:
Greater than 	>
less than 	<

Logical Connectives:
and 		/\
or		\/
not		~

Type Comparisons:
supertype	>
subtype		<
alike		-

Should default operators be special characters or should they follow normal symbol rules?

Brackets are special characters because they are used as boundaries.
The vertical bar is also a special character because it's used with modules.
But what about operators such as pointers?


What about foreign function calls and ABI mis-matches?
honestly just make a foreign function call convention which matches the convention of one of GCC, MSCV, or Clang.
should ASC compile directly to assembly? Yes, because it employs special context manipulation which isn't possible in any other language.

what is type specification?

Ex:
	T = [x y z]
	var:T(x) `what does this mean?`


say you want a symbol with parentheses in it.
the symbol quotation operator drops special notations and just does visible vs. spaces

`(parens)

now to use the symbol as a symbol, evaluate it with parentheses

( `(parens) )

actually parentheses randomly unquoting symbols is dangerous.
i need an unquote operator.

symbol quote:	`
symbol unquote: ``
`(symbol)



primitive operators:

symbol quotation
symbol unquote

entity location
access location

entity storage requirements
entity cardinality

entity index subscript
entity member access

type composition is just a sequence.
In normal type systems, dependent types combine types and values, but in
pure type systems, types and values are types.
Take the classic List dependent type example. There's an abstract list type
where the definition depends on a length value.
In a pure type system, the list type is a type, and the length value is also a
type.
List types then become type tuples.
The constraint that the List is the "interface" of the type and the length is
part of the type information becomes a meta-logical decision.
Now list types are simply a normal list type with a length just like how they're
defined using records in other languages.

So now if unit types are
	U = [U]
and type superpositions are
	S = [t t t]

then type compositions are
	C = [k.l.m]
where
	C..1 == k
	C..2 == l
	C..3 == m
and
&{x:p y:q z:r} == [p.q.r]



dependent types means that there's some value attached to type information which can be erased.
if types are completely tied to structs as they exist during a program, type information can't be erased.
how to attach random types to stuff which don't affect the interface?
how to erase types?

Ex:
asserting that a list is longer without necessarily keeping track of the length.

SLTN:
Dependent types exist because of the explicit notion of type erasure.
The types which depend on terms are discarded once the terms are proven sound.
Pure type systems don't need this because everything is types. Terms are just
unit types.

Type erasure reduces to proving equality between two programs.
For instance, functions across a dependent list type can be proven using a
dependent list length annotation. But the same action can be achieved in a pure
type system by proving the equality of functions over a list with an explicit
length and functions over a list without an explicit length.
Basically any compilation level optimization becomes a form of type erasure.

Now I just need to prove equivalence between things.

1 + 1 = 2

f([Nat > 1]) = 0


================================================================================
SUPER IMPORTANT
================================================================================

support term rewriting instead of f expression style macros?

What's the difference?

macros involve invoking expressions which are matched and replaced.

term rewriting involves substituting portions of the syntax tree and requires
proof of equivalence.

a simple example is constant folding. how would I explicitly define constant
folding.

1 + 1 = 2
Constant + Constant = (Constant + Constant)
; (x:Constant `+ y:Constant) = x + y `enforces all constant addition is performed at compilation`

Say a function f of a certain expression is rewritable as a separate function application
; (`f `( x:k `) ) = g(x)

what if I want to say that a function f can be replaced with a function g
; (`f `( ,x `) ) = g(x)
; ('f ( ,x )') = g(x)

; ; 'f ( ,x )' = g(x)

; 'a' = b `rejected because terms are not equal`

SKIP ALL THAT, JUST MAKE EXPRESSIONS COMPARABLE

Comparing constant expressions is simple

1 + 1 = 2

(. (x = 1) = x + 1) = 2

What about variables?t can be equal to any unit which is a subtype of the natural numbers`
x:Natural = 1
x = 1 `x can only equal one here because the most accurate type is the unit type, 1`
`x being typed as a Natural means that i
x:Natural = 2

Register + 1 = 2 = 1 + Register

Natural + Natural = Natural + Natural
x:Natural + y:Natural = y:Natural + x:Natural

equality rules:
	- the expressions on both sides must evaluate to the same thing or else
	  a semantic error occurs.

Types are multisets of features.
Superpositions are fuzzy multisets.
Collections are just types with features.
A collection of types is the same as a single type with all the features of those types.
Imagine you had tgree squares in 2D space.
Tge type of each square corresponds to the shape and position.
The type of a collection of squares is simply the type of three square definitions.
Trivially:
	a:[x]
	b:[y]
	c:[a.b]
	d:[x.y]
	c = d


rather than evaluation, make the execution model be term rewriting.
it's a basic switch and doesn't affect stuff like modules, functions, or
collections.
the switch still affects what's fundamentally possible.
it allows for full unification and equivalence expressions rather than simple variable binding.


similar to tail call recursion, what's an optimization for functions that allows modification in place.

n = 0
f(x) =	? n = 9
	 n
	 f(x + 1)
f(n)

expression rewriting allows for visual programming in a node style.

how to mutate variables.
structural rules, weakening, contraction, exchange.
language doesn't do entailment.
all propositions which are proven true based on other propositions.
different than sequent calculus.


how do equalities correspond to entailment?

each equality is probably true or probably false.
equalities correspond to individual sequents.
entailment is the conclusion of the program.

structural rules for sequent calculus don't apply to unification.
for example, given the equalities
A: x = y
B: y = z
C: z = x

Produces the sequents
A, B |- C
B, C |- A
C, A |- B

and each sequent involves the cut rule so the sequent calculus version explodes.
much easier to create binding rules regarding variables.
operations are bind and drop

no sequent structural rules.
equivalences are different.
just variable binding and unbinding.
if a variable appears by itself in an equivalence, opposite an expression, it becomes bound.
otherwise an equivalence relation is established

there's an expression.
the expression is made out of symbols.
symbols are made out of characters.
notations are used to decide how expressions are formed from symbols.

functions are a higher order version of equivalences.
it binds variables within the function call syntax.
Take this function example,
	f(x : Register) = x + 1
	^ ^   ^           ^   ^
	1 2a  3           2b  4
1 is the name of the function. This variable is bound as a function name.
2a is a variable bound as a function parameter
3 is the type of the parameter
2b is the parameter as it is bound in the definition of the function
4 is a constant

according to equality, you can have two functions which are named the same thing, but differ in types. 
Such as,
	f(x:T) = y
	f(x:t) = z
However, two definitions which are equal levels of specificity and are not unifiable, are not accepted.
	f(x:T) = y
	f(x:T) = z
or
	f(x) = n
	f(x) = n

what about anonymous functions or things with don't depend on binding?
functions aren't just equivalences, they're entities which affect context.

equivalences are variable bindings
higher order equivalences are cases.

x = 1
f(x) = y + x

================================================================================

New Function syntax:

because ASC has equality expressions, something like,
	f(x) = x
also counts as an equality.
This creates a problem because equality expressions evaluate to a boolean even 
if they bind variables.
So now I need a lambda constructor which does not rely on the equal sign or
binding.

lambda syntax needs a way to declare multiple parameters and a definition.
say parameters x and y. Output will always be the last expression so parameters
aren't necessary.

1. Function type way
	x y -> x + y

2. Lambda Calculus way
	/. x y . x + y

3. anonymous function way
	(x y) x + y

4. alternate anonymous function
	(x y) -> x + y

5. Without lambda symbol
	(x y) . x + y

6. Using commas
	x, y -> x + y

7. currying (ew) ((ASC explicitly supports collections so functions should work
over collections too
	x -> y -> x + y

8. {x y} -> {x + y}

9. x, y . x + y

10. , x y . x + y

11. / x y . x + y

12. * x y . x + y

13. | x y . x + y

14. (x y) . x + y

Modules:
	| ... | ...  | ... |
Types:
	[ ... ]
Collections:
	{ ... }
Functions:
	( ... )

15. (x y -> x + y)

16. (x y . x + y)

17. (x y) -> x + y

parens followed by arrow seems best and most recognizable.
A function tuple followed by an arrow
although using currying is interesting.
or instead of currying, allow collections on either side.
For example,
	x -> x + 1
or 
	{x y} -> x + y
and 
	{x y} -> {z = x + y   z + 1}

and then function application is simply juxtaposition
	f = {x y} -> x + y
	f(x y)


mutation/assignment operator, _ << _ 
is separate from equality and binding.
instead of assigning variable, updates value.
call it  "clobber".
only works on Data.
x:Register = 1
x = 1
x << 2
x = 2


function is not equality, it's rewriting.
In math, 
	f(x) = ...
is used as both definition and to refer to the function object itself,
as soon as higher order functions are used, function names become variable bindings again.

f(x) = -> x + 1
f(x) = x -> x + 1

function is a context to evaluate some expressions.

x -> x + 1

(x y) -> x + y
is actually 
{x y} -> x + y
{x y} -> {y + 1  x + 1}

f = {x y} -> x + y
f = {x:T y:T} -> 
(x) . x + 1
(x y) . x + y
(x y) -> x + y


how to do multiple parameter functions?

what are functions? they're contexts.
you can inline every function and still get the same behavior.

there's different notations though.
do you want to declare all types and parameters up front, or have them be natural parts of an expression?

	x:t -> y:T
vs.
	x:t -> t {y}

functions are important and need to be distinct from other syntax.
just write down what I want them to look like.

f = x -> x + 1
f(x) -> x + 1
(x) -> x + 1

f(x:T) = -> x + 1
f = x:n -> y
f = x:m -> y

in geometric meta language, there's transformations between features.
	x = [x]
	y = [y]
	x -> y
it can be multiple types as in
	x = [x] y = [y] z = [z] 
	p = [p] q = [q] r = [r]
	x.y.z -> p.q.r

polymorphic functions are piecewise case-matching over different parameters.

a transformation is 
	x -> y
a function is
	f = x -> y
where f is bound and x is unbound such that
	f(p) => (x = p) -> y

what does it mean to parameterize something?
parameterization adds independent variables.

a variable becomes bound at the point in a program where it is certain that 
the variable can only be substituted with a single existing entity.

variables are bound using equality and functions.

--------------------------------------------------------------------------------


functions are transformations between features.
functions can transform a collection of features.
the syntax is 
	x -> y

what is a polymorphic function?
it's a collection of transformations which are mapped piecewise to cases of
parameter types.

	t_a = []
	t_b = []
	f(x) = -> p(x)
	f(x:t_a) = -> q(x)
	f(x:t_b) = -> r(x)

	f = {x y} -> {g(x) m(y)}
same as
	f(x y) = -> {g(x) m(y)}

Is notation a lambda or an equality.
probably an equality because you don't necessarily need a function for everything.

; x 'yuck y ; = yuck-fun (x y)


--------------------------------------------------------------------------------

no comments, annotations instead.
you can ask the compiler to look up documentation about bound variables.
annotation operator is ` and it takes a string after it.
so 
	x = 1 
	x ` "bound to 1"

--------------------------------------------------------------------------------
how to explain the top level?
can't assume that compiler writers will know how to evaluate expressions.
there's no such thing as order of operations.
all expressions are left associative because things are read left-to-right.

prefix stuff is always done before suffix stuff. THIS IS GOING TO BE ANNOYING THO
take this example:
	x = {1 2 3}
	y = {1 2 3}
	y.0 + x.0 = ((y.0) + x).0
	`when what i want is:` (y.0) + (x.0)
is this order of operations? yes.
do i do order of operations for notations? maybe.


what about supertypes.

	T = []
	U = [T]
	V = [T]
	x:T

associativity based on types.

say there's operations across some type

; x `+ y = add(x y)

now depending on the types of x and y, you can change associativity.
	; x:T `+ y:Expression(T) = add(x y)
is left-associative because the Expression syntax type makes explicit that 
some other stuff must be evaluated first.
	; x:Expression(T) `* y:T = add(x y)
is right-associative.

a + b + c = (a + (b + (c)))
x * y * z = (((x) * y) * z)

This also helps enforce general operator precedence.
Take for example addition and collection access.

given an expression without precedence:
	1 + x.y = (1 + x) . y
but when addition is defined as 
	; x:Expression(Number) + y:Expression(Number) = add((x) (y))
then 
	1 + x.y = (1) + (x.y)
due to the definition of Expression being an entire notation, not a constant, variable
or symbol.

That gets me into syntax types because there's several...
- Character:
	Everything that can be written uses one or more characters
- Symbol:
	A sequence of characters delimited by blanks (unless some other delimiting rule is applied)
- Constant:
	A specific sub-class of symbols which correspond to numeric values
- Terminal:
	A symbol which represents an operation and is not evaluated.
- Variable
	A symbol which evaluates to an entity.
- Notation
	A single operation supplied with operands which are not other notations.
- Expression
	A single notation supplied with operands which may be other notations.

--------------------------------------------------------------------------------

what's the deal with equality, is it full unification?
how is this enforced?
anything that requires evaluation is reserved for runtime checks? idk

say
	1 = 1
those are both constants which are evaluated at compile time.
unification is special though, so does it get clobbered by macros? yes

equality has to do with variables and determining which entity a variable evaluates to.
a special case of equality is assignment.
if an equality is written where only one side has a single variable, then that variable is always bound to whatever is on the other side.
if there are previous bindings which are not possible with the new binding, those bindings are undone.

given bound and unbound variables, there's also the notion of dependent and independent variables.

there's also the special case of function polymorphism. i.e.
	f(x:T) = -> g(x)
	f(x:U) = -> h(x)

so variable binding is 
	x = 1
where x is bound to 1

Independent variables allow for constraints and refinements, but how to specify that independent variables are being used?
Take the expressions,
	x = 1
	y + x = z + x

so the three things I want to do with variables:
- bind them
- use them independently of their bindings
- automatically drop previous bindings that conflict with a new one

binding variables:
	x = 1
	y = 2
	b = 3
equality comparison:
	x = 1
	(x) = 1
using independent variables
	z = 1
	f(z) + x = g(z) + y

but how to use independent variables which are the same symbol as bound variables?

--------------------------------------------------------------------------------

very excellent analogy:

ASC is a tool, just like any other.
More specifically, ASC is like an angle grinder. 
Angle grinders are used in almost every craft because they are powerful, precise, and highly versatile.
The only stipulation is that you have to know how to use one properly.
For example, the object you're grinding must be held in a stable position and there's only a few safe ways to hold the angle grinder.
If you use one the right way, angle grinders come with many safety features so that you will never be surprised or hurt.
Unfortunately most craftspeople don't bother to learn proper safety techniques before they use an angle grinder.
This often results in cases of permanent maiming or even death.
When you use ASC properly and safely, you'll create marvels of both beauty and practicality.
Make sure to learn what proper use and safety mean for ASC or else you and others could get hurt.

--------------------------------------------------------------------------------

what things are declarative in my language?
equality statements are declarative.
they affect what things may be true in a context.
do lambdas affect things? no, they're entities.
there's no syntactic unification because lambdas don't rewrite, they evaluate.
thus there's evaluational unification.

what about lambdas as used to make independent variables?
usually you say
	y = x + 1
where y represents the return value of some f(x) and x is independent.
but in ASC, you would have to do
	y = f(x) = -> x + 1
but what about non-functional independent variables?
	x + 1 = y + 2
this would look like
	{x y} -> x + 1 = y + 2
The unification is now stuck inside a lambda context.

what I want is quantification.
higher order quantification?
how does this work with types?

existential involves binding a variable so
	x = 1
is the same as
	"there exists an x which is 1"

quantification is... types?

is this higher order logic, or lower order logic.
I can't do pure existential or universal quantification.

here's the thing though, unification can be reduced
	x + 1 = y - 2
	x = y - 2 - 1
	y = x + 1 + 2


so how do I do binding in my language?
is it explicit, or is it implicit as part of equality and unification?

unification takes two expressions
; x:Expression `= y:Expression ; = ? (x) = (y) True False

--------------------------------------------------------------------------------

how to talk about collections.
collections are 
	{ ... }
things inside them can be named
	{ a b c }
they can be given values 
	{ a = 1 b = 2 c = 3 }

but now I want to talk about sequences.
its a collection where everything is the same type and only the cardinality matters
what do those look like?

using the sequence type
	Sequence(3 Byte)
--------------------------------------------------------------------------------

dependent types?

stuff where types can depend on values.
that's called a function.
to make a list type that depends on a length, you define the list type as a function of length.

what does polymorphism look like
well the function form 
	( _ ) -> _
means that the function is evaluated immediately (a let notation)
when you supply the function with variables, but on new bindings, then it enforces those variables to be independent on the RHS
	((x = 1) -> x + 1) = 2
	((x) -> x + 1) 

(x) -> f(x) = x -> i
(x:P) -> f(x) = x -> j
(x:Q) -> f(x) = x -> k
(x:Q) -> f(x):l = x -> l

--------------------------------------------------------------------------------

unification algorithm:

unification is an equality of two expressions which returns a boolean true if the expressions are equal or a boolean false if they are not equal.
	(1 = 1) = true
	(1 = 2) = false
unification is evaluational so two expressions must yeild equivilant entities otherwise the unification will not hold.

unification is effectful because it will implicitly bind variables.
so in 
	x + 1 = 3
x is bound to two. And in
	g(y) = f(2)
y is bound to a value where if g is applied to it, it's equivalent to f applied to 2

there is a special case of binding where a variable appearing by itself on one side of the equality will always be bound to the other side
any previous bindings that conflict with the new binding are discarded.

--------------------------------------------------------------------------------

